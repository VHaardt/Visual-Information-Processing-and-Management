{"cells":[{"cell_type":"markdown","source":["# **PDF Image Extractor and Classification**<br/>\n","**Master's Degree in Data Science (A.Y. 2023/2024)**<br/>\n","**University of Milano - Bicocca**<br/>\n","\n","Vittorio Haardt, Luca Porcelli"],"metadata":{"id":"SN58iM5MBw1L"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"z9-_aCTMvagd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706521343639,"user_tz":-60,"elapsed":23275,"user":{"displayName":"Vittorio Haardt","userId":"07881706535126483127"}},"outputId":"69f2568e-120e-4f19-ba62-45df8caa5f9a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["## Installazione pacchetti e caricamento librerie"],"metadata":{"id":"XkJMHvBGCC5L"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11619,"status":"ok","timestamp":1706521355254,"user":{"displayName":"Vittorio Haardt","userId":"07881706535126483127"},"user_tz":-60},"id":"MI3N_I_hlxdv","outputId":"b488a5a1-34e2-4718-8cca-c6869dbcabb4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting PyMuPDF\n","  Downloading PyMuPDF-1.23.19-cp310-none-manylinux2014_x86_64.whl (4.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting PyMuPDFb==1.23.9 (from PyMuPDF)\n","  Downloading PyMuPDFb-1.23.9-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (30.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.6/30.6 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: PyMuPDFb, PyMuPDF\n","Successfully installed PyMuPDF-1.23.19 PyMuPDFb-1.23.9\n"]}],"source":["pip install PyMuPDF"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9836,"status":"ok","timestamp":1706521365084,"user":{"displayName":"Vittorio Haardt","userId":"07881706535126483127"},"user_tz":-60},"id":"MYQXzD3fD1Uq","outputId":"89c37d34-f3a7-43e0-e2de-3ae9fce68ed7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pytesseract\n","  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n","Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (23.2)\n","Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (9.4.0)\n","Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.23.5)\n","Installing collected packages: pytesseract\n","Successfully installed pytesseract-0.3.10\n"]}],"source":["pip install pytesseract opencv-python"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26571,"status":"ok","timestamp":1706521391649,"user":{"displayName":"Vittorio Haardt","userId":"07881706535126483127"},"user_tz":-60},"id":"FXMMHV5iFHEa","outputId":"6c9ed27e-248a-45f9-a134-0afec54e835a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","The following additional packages will be installed:\n","  tesseract-ocr-eng tesseract-ocr-osd\n","The following NEW packages will be installed:\n","  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n","0 upgraded, 3 newly installed, 0 to remove and 31 not upgraded.\n","Need to get 4,816 kB of archives.\n","After this operation, 15.6 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1,591 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2,990 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n","Fetched 4,816 kB in 3s (1,799 kB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package tesseract-ocr-eng.\n","(Reading database ... 121671 files and directories currently installed.)\n","Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n","Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n","Selecting previously unselected package tesseract-ocr-osd.\n","Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n","Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n","Selecting previously unselected package tesseract-ocr.\n","Preparing to unpack .../tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n","Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n","Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n","Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n","Setting up tesseract-ocr (4.1.1-2.1build1) ...\n","Processing triggers for man-db (2.10.2-1) ...\n","Requirement already satisfied: pytesseract in /usr/local/lib/python3.10/dist-packages (0.3.10)\n","Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (23.2)\n","Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (9.4.0)\n"]}],"source":["!sudo apt-get install tesseract-ocr\n","!pip install pytesseract"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JwZJxt9bmWT1"},"outputs":[],"source":["import fitz  # PyMuPDF\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from skimage import data\n","from skimage import color\n","from skimage import morphology\n","from skimage import segmentation\n","import copy\n","from scipy.spatial import ConvexHull\n","import pytesseract\n","import tqdm\n","from PIL import Image\n","import math\n","import keras\n","import tensorflow as tf"]},{"cell_type":"markdown","metadata":{"id":"UsWtYSb2RFI_"},"source":["# Funzione di Estrazione"]},{"cell_type":"markdown","metadata":{"id":"UbIO3eMfRgA-"},"source":["## Funzioni di supporto"]},{"cell_type":"markdown","source":["### Pagine PDF"],"metadata":{"id":"rY-yG60mJbbh"}},{"cell_type":"markdown","source":["La funzione `pdf_to_images` per estrarre una lista contenente ogni pagina del pdf come immagine (np.array)"],"metadata":{"id":"FTrYUBqWCy9C"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"vj_MW5FLRfgA"},"outputs":[],"source":["def pdf_to_images(pdf_path, resolution=300, color_format=\"rgb\"):\n","    pdf_document = fitz.open(pdf_path)\n","    images = []\n","    for page_number in range(pdf_document.page_count):\n","        page = pdf_document.load_page(page_number)\n","        pixmap = page.get_pixmap(matrix=fitz.Matrix(resolution/72.0, resolution/72.0), clip=page.rect, colorspace=color_format)\n","        img_array = np.frombuffer(pixmap.samples, dtype=np.uint8).reshape((pixmap.height, pixmap.width, 3))\n","        images.append(img_array)\n","    pdf_document.close()\n","    return images"]},{"cell_type":"markdown","source":["### Maschere"],"metadata":{"id":"D93YZc-oJhi0"}},{"cell_type":"markdown","source":["La funzione `mask_calculation` che prende un'immagine di una pagina PDF come input e la elabora per creare una maschera booleana in cui i pixel con un'intensità luminosa superiore a 0.99 vengono considerati parte dell'oggetto principale.\n","\n","Rimuove eventuali piccoli dettagli o oggetti che potrebbero essere indesiderati, basandosi su una dimensione minima di 500 pixel. La maschera viene ulteriormente elaborata per rimuovere i buchi al suo interno.\n","\n","Viene eseguita un'operazione di apertura sulla maschera. L'apertura è una combinazione di erosione seguita da dilatazione. Un elemento strutturante circolare con un raggio di 3 pixel viene utilizzato durante questa operazione. Serve a eliminare ulteriori dettagli e a garantire una forma più uniforme dell'oggetto principale.\n","\n","La funzione restituisce la maschera elaborata.\n","\n","[[Source](https://scikit-image.org/docs/stable/auto_examples/segmentation/plot_mask_slic.html)]"],"metadata":{"id":"2bzfkQ3FDWbk"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"8RXu3-3oR1TS"},"outputs":[],"source":["def mask_calculation(pdf_page):\n","  lum = color.rgb2gray(pdf_page)\n","  mask = morphology.remove_small_holes(morphology.remove_small_objects(lum > 0.99, 500),500)\n","  mask = morphology.opening(mask, morphology.disk(3))\n","  return mask"]},{"cell_type":"markdown","source":["### Divisione maschere"],"metadata":{"id":"vnrrK7gNJl6q"}},{"cell_type":"markdown","source":["La funzione `mask_separation` è progettata per dividere una maschera complessa in maschere più semplici attraverso tre fasi di ricerca:\n","\n","- Ricerca Orizzontale Iniziale:\n","Divide le maschere a diverse altezze rispetto alla maschera principale.\n","- Ricerca Verticale:\n","Suddivide le maschere generate nella fase precedente in maschere con posizioni laterali diverse.\n","- Ricerca Orizzontale Aggiuntiva per Pulizia:\n","Esegue un altro ciclo di divisione orizzontale per pulire ulteriormente le maschere risultanti.\n","\n","Durante l'esecuzione della funzione, le maschere troppo piccole vengono eliminate"],"metadata":{"id":"ggKaCmAiEz6E"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"j4v8QB1nSKKO"},"outputs":[],"source":["def mask_separation(img, mask):\n","  maskere = []\n","  maskere_fin = []\n","  dim_img = img.shape[0]*img.shape[1]\n","  while not np.all(mask):\n","      found_all_true = False\n","      first_false = False\n","\n","      mask2 = copy.deepcopy(mask)\n","      for i, row in enumerate(mask2):\n","          if False in row and not first_false:\n","              first_false = True\n","          elif first_false:\n","              if False not in row:\n","                  mask2[i] = [True] * len(row)\n","                  found_all_true = True\n","              elif not found_all_true:\n","                  pass\n","              else:\n","                  mask2[i] = [True] * len(row)\n","\n","      maskere.append(mask2)\n","      mask = mask2 ^ mask\n","      mask = ~mask\n","\n","  for m in maskere:\n","    mask_t = m.T\n","    while not np.all(mask_t):\n","        found_all_true = False\n","        first_false = False\n","\n","        mask2 = copy.deepcopy(mask_t)\n","\n","        for i, row in enumerate(mask2):\n","            if False in row and not first_false:\n","                first_false = True\n","            elif first_false:\n","                if False not in row:\n","                    mask2[i] = [True] * len(row)\n","                    found_all_true = True\n","                elif not found_all_true:\n","                    pass\n","                else:\n","                    mask2[i] = [True] * len(row)\n","\n","        if np.count_nonzero(mask2.T == False) > dim_img/50:\n","          maskere_fin.append(mask2.T)\n","\n","        mask_t = np.logical_xor(mask2, mask_t)\n","        mask_t = ~mask_t\n","\n","  maskere_fin_pul = []\n","  for ma in maskere_fin:\n","      mask_t = ma\n","      dim_img = img.shape[0] * img.shape[1]\n","\n","      while not np.all(mask_t):\n","          found_all_true = False\n","          first_false = False\n","\n","          mask2 = copy.deepcopy(mask_t)\n","\n","          for i, row in enumerate(mask2):\n","              if False in row and not first_false:\n","                  first_false = True\n","              elif first_false:\n","                  if False not in row:\n","                      mask2[i] = [True] * len(row)\n","                      found_all_true = True\n","                  elif not found_all_true:\n","                      pass\n","                  else:\n","                      mask2[i] = [True] * len(row)\n","\n","          if np.count_nonzero(mask2.T == False) > dim_img / 100:\n","              maskere_fin_pul.append(mask2)\n","\n","          mask_t = np.logical_xor(mask2, mask_t)\n","          mask_t = ~mask_t\n","  return maskere_fin_pul"]},{"cell_type":"markdown","source":["### Raffinamento maschere ed estrazione immagini"],"metadata":{"id":"mnedn5MKJpTB"}},{"cell_type":"markdown","source":["La Funzione`single_img`, estrae regioni specifiche da un'immagine di input sulla base di una lista di maschere. Vediamo una spiegazione dettagliata:\n","\n","La funzione itera sulla lista di maschere fornita come input.\n","Per ogni maschera:\n","     - Trova i contorni della maschera utilizzando la funzione `cv2.findContours`.\n","     - Estrae i vertici convessi dell'inviluppo convesso dei contorni trovati.\n","     - Calcola i valori minimi e massimi dei vertici convessi per definire un rettangolo delimitatore, con `ConvexHull`.\n","     - Esegue il ritaglio dell'immagine di input utilizzando il rettangolo delimitatore.\n","\n","Viene calcolata la dimensione della regione ritagliata e confrontata con la dimensione totale dell'immagine iniziale. Solo se la dimensione della regione ritagliata è maggiore dell'1% della dimensione totale dell'immagine iniziale.\n","\n","La funzione restituisce una lista contenente le immagini estratte sulla base delle maschere fornite."],"metadata":{"id":"nnY9sz9eIqkh"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"dsNmAzbDSkfU"},"outputs":[],"source":["def single_img(immagine, lista_maschere):\n","  single_images = []\n","  dim_img = immagine.shape[0]*immagine.shape[1]\n","  for i in lista_maschere:\n","    contours, _ = cv2.findContours(i.astype(np.uint8), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n","    corners = contours[1].reshape(-1, 2)\n","    hull = ConvexHull(corners)\n","    convex_hull_vertices = corners[hull.vertices]\n","    min_x, min_y = np.min(corners, axis=0)\n","    max_x, max_y = np.max(corners, axis=0)\n","    cropped_image = immagine[min_y:max_y, min_x:max_x]\n","    dimensione = cropped_image.shape[0]*cropped_image.shape[1]\n","    if dimensione > dim_img / 100:\n","      single_images.append(cropped_image)\n","  return single_images"]},{"cell_type":"markdown","source":["### Rimozione testi"],"metadata":{"id":"BGbBjz-eJwqI"}},{"cell_type":"markdown","source":["La funzione `filter_text` filtra un elenco di array di immagini sulla base della quantità di colori unici presenti. Ecco una spiegazione dettagliata:\n","\n","Per ciascun array di immagine nella lista:\n","     Trova i colori unici nell'immagine.\n","     - Valuta se il numero di colori unici è inferiore a 10000 e memorizza il risultato.\n","     - Aggiunge il valore booleano ad una lista.\n","\n","Viene creata una lista contenente solo le immagini con più di 10000 colori unici."],"metadata":{"id":"xv4lqWWbJ0c0"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"7hISJm4wuIZJ"},"outputs":[],"source":["def filter_text(lista_array):\n","  if not lista_array:\n","    return []\n","  list_ok = []\n","  for im in lista_array:\n","    if len(im.shape) == 3:\n","      im = im.reshape((-1, 3))\n","    colori_unici = np.unique(im, axis=0)\n","    value = len(colori_unici) < 10000\n","    list_ok.append(value)\n","    output_images = [valore for valore, include in zip(lista_array, list_ok) if not include]\n","  return output_images"]},{"cell_type":"markdown","metadata":{"id":"lcU9ndT8RiWb"},"source":["\n","## Funzione di Estrazione"]},{"cell_type":"markdown","source":["La funzione `images_from_pdf` incorpora le funzioni precedenti per estrarre efficacemente le immagini da un pdf."],"metadata":{"id":"WBIf4ZZ2KrDW"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"oJiwtk0RRKJL"},"outputs":[],"source":["def images_from_pdf(pdf_path):\n","  EXTRACTED_IMGS = []\n","  #estraggo immagine per ogni pagina\n","  pdf_images = pdf_to_images(pdf_path)\n","  # per ogin pagina\n","  for im in tqdm.tqdm(pdf_images, desc='Processed PDF pages'):\n","    #dimensione pagina\n","    dim_im = im.shape[0]*im.shape[1]\n","\n","    #calcolo maschera\n","    mask = mask_calculation(im)\n","\n","    # separo in piu maschere divise\n","    li_masks = mask_separation(im, mask)\n","\n","    #applico le maschere\n","    li_imgs = single_img(im, li_masks)\n","\n","    #tologo le immagini con solo testo\n","    imgs_no_text = filter_text(li_imgs)\n","\n","    #aggiungo alla lista\n","    for i in imgs_no_text:\n","      EXTRACTED_IMGS.append(i)\n","  return EXTRACTED_IMGS"]},{"cell_type":"markdown","metadata":{"id":"0QwCbdRWVY3_"},"source":["## Estrazione Immagini"]},{"cell_type":"markdown","source":["Applicazione della funzione di estrazione delle immagini sul PDF."],"metadata":{"id":"Pm66SqsPnEdG"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":388414,"status":"ok","timestamp":1706521794542,"user":{"displayName":"Vittorio Haardt","userId":"07881706535126483127"},"user_tz":-60},"id":"0l8tsKRlVWtM","outputId":"17e85d66-2554-49c3-d3ad-31b377dbe0a5"},"outputs":[{"output_type":"stream","name":"stderr","text":["Processed PDF pages: 100%|██████████| 21/21 [06:13<00:00, 17.78s/it]\n"]}],"source":["immagini_estratte = images_from_pdf('/content/drive/MyDrive/VIPM/PDF part/food_text.pdf')"]},{"cell_type":"markdown","source":["Visualizzazione delle immagini estratte."],"metadata":{"id":"4FpZtL7fnK9x"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1_K4KmntX1LGm_W2_h_S0n4-Jub9VidIX"},"executionInfo":{"elapsed":21910,"status":"ok","timestamp":1706521816448,"user":{"displayName":"Vittorio Haardt","userId":"07881706535126483127"},"user_tz":-60},"id":"8fT-Vi30V35h","outputId":"7be3000f-6ce8-4b17-fff4-c58379fd4e92"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["num_masked_images = len(immagini_estratte)\n","num_cols = 4\n","num_rows = math.ceil(num_masked_images / num_cols)\n","fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 5*num_rows))\n","axes = axes.flatten()\n","for i, ax in enumerate(axes[:num_masked_images]):\n","    ax.imshow(immagini_estratte[i])\n","for j in range(num_masked_images, len(axes)):\n","    fig.delaxes(axes[j])\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"GmNAzurNehl8"},"source":["# Classificazione Immagini"]},{"cell_type":"markdown","source":["Caricamento modello previsionale."],"metadata":{"id":"jP-TRErKocPQ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"iD23R0uGeUle"},"outputs":[],"source":["food_nonfood = keras.models.load_model('/content/drive/MyDrive/VIPM/Models/Model_PDF.Keras')"]},{"cell_type":"markdown","source":["Visualizzazione risultati di classficazione."],"metadata":{"id":"cxw26AsJpFXW"}},{"cell_type":"code","source":["num_masked_images = len(immagini_estratte)\n","num_cols = 4\n","num_rows = math.ceil(num_masked_images / num_cols)\n","fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 5*num_rows))\n","axes = axes.flatten()\n","for i, ax in enumerate(axes[:num_masked_images]):\n","    resized_image = Image.fromarray(immagini_estratte[i]).resize((224, 224))\n","    image_array = tf.keras.preprocessing.image.img_to_array(resized_image)\n","    image_array = tf.expand_dims(image_array, 0)  # Aggiungi una dimensione per la batch\n","    # Effettua la previsione\n","    predictions = food_nonfood.predict(image_array)\n","    # Interpreta i risultati\n","    predicted_class = tf.argmax(predictions[0]).numpy()\n","\n","    ax.imshow(immagini_estratte[i])\n","    if predicted_class == 0:\n","        pred = \"Food\"\n","        title_color = \"darkgreen\"  # Colore verde scuro per Food\n","    else:\n","        pred = \"Non-Food\"\n","        title_color = \"blue\"  # Colore blu per Non-Food\n","    ax.set_title(pred, color=title_color)  # Imposta il colore del titolo\n","for j in range(num_masked_images, len(axes)):\n","    fig.delaxes(axes[j])\n","plt.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1n5QOKdVk65cal8rhYjAwobpoP1Rm8Gwq"},"id":"bSEmirETuERN","executionInfo":{"status":"ok","timestamp":1706522008552,"user_tz":-60,"elapsed":34737,"user":{"displayName":"Vittorio Haardt","userId":"07881706535126483127"}},"outputId":"f22c6e93-151e-4aad-ebc6-95a1bb3d68a9"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}],"metadata":{"colab":{"provenance":[],"collapsed_sections":["UbIO3eMfRgA-","lcU9ndT8RiWb"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}