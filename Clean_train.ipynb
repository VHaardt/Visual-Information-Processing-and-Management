{"cells":[{"cell_type":"markdown","source":["# **Clean train**<br/>\n","**Master's Degree in Data Science (A.Y. 2023/2024)**<br/>\n","**University of Milano - Bicocca**<br/>\n","\n","Vittorio Haardt, Luca Porcelli"],"metadata":{"id":"HKWAYUUWXPTL"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IWEz3zdhnWvg","executionInfo":{"status":"ok","timestamp":1706605541663,"user_tz":-60,"elapsed":24510,"user":{"displayName":"Luca Porcelli","userId":"09580591037146988201"}},"outputId":"9ac95181-ca33-4b6f-cdb7-f696a8d27ebf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!unzip \"/content/drive/MyDrive/VIPM/Dataset/train_set.zip\" -d train"],"metadata":{"id":"l4PdecxUnU9y"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ThrjFydRsG3C"},"outputs":[],"source":["import pandas as pd\n","from datasets import concatenate_datasets, load_dataset, load_from_disk\n","from datasets import DatasetDict\n","import math\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import operator\n","from skimage.color import rgb2gray\n","from skimage.feature import local_binary_pattern\n","from tqdm import tqdm\n","import os\n","import shutil"]},{"cell_type":"markdown","metadata":{"id":"97QRqz0isG3H"},"source":["# Data Import"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"referenced_widgets":["a72f7c0e5e9749efae119ebc5eccf930","59c8d2a2735d4159a09b7a05f4a6396e"]},"id":"Bpiu84THsG3J","outputId":"c625b0d3-507b-4c1f-aecf-9377dbda6f50"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a72f7c0e5e9749efae119ebc5eccf930","version_major":2,"version_minor":0},"text/plain":["Resolving data files:   0%|          | 0/118475 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"59c8d2a2735d4159a09b7a05f4a6396e","version_major":2,"version_minor":0},"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["dataset = load_dataset('imagefolder', data_dir=\"/content/train/train_set\")"]},{"cell_type":"markdown","metadata":{"id":"HuY4A66LsG3N"},"source":["# Support Functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M2y4UjAqsG3P"},"outputs":[],"source":["def coOrdinateTransform(arr, width, height):\n","        Lab = np.zeros(3 * width * height).reshape(width, height, 3)\n","        for i in range(width):\n","            for j in range(height):\n","                Lab[i][j][0] = arr[i][j][0]\n","                Lab[i][j][1] = arr[i][j][1]\n","                Lab[i][j][2] = arr[i][j][2]\n","\n","                Lab[i][j][1] = arr[i][j][1] + 127.0\n","                if Lab[i][j][1] >= 254.0:\n","                    Lab[i][j][1] = 254.0 - 1.0\n","                if Lab[i][j][1] < 0:\n","                    Lab[i][j][1] = 0\n","\n","                Lab[i][j][2] = arr[i][j][2] + 127.0\n","                if Lab[i][j][2] >= 254.0:\n","                    Lab[i][j][2] = 254.0 - 1.0\n","                if Lab[i][j][2] < 0:\n","                    Lab[i][j][2] = 0\n","        return Lab\n","\n","def maxgrad_and_mingrad_Lab(arr,num,wid,hei):\n","        gxx = gyy = gxy = 0.0\n","        rh = gh = bh = 0.0\n","        rv = gv = bv = 0.0\n","        theta = 0.0\n","        ori = np.zeros(wid * hei).reshape(wid, hei)\n","        for i in range(1, wid - 1):\n","            for j in range(1, hei - 1):\n","                rh=arr[i-1,j+1,0] + 2*arr[i,j + 1,0] + arr[i+1, j+1,0] - (arr[i-1, j - 1, 0] + 2 * arr[i,j-1, 0] + arr[i + 1, j - 1, 0])\n","                gh=arr[i-1,j+1,1] + 2*arr[i,j + 1,1] + arr[i+ 1,j+1,1] - (arr[i-1, j - 1, 1] + 2 * arr[i,j-1, 1] + arr[i + 1, j - 1, 1])\n","                bh=arr[i-1,j+1,2] + 2*arr[i,j + 1,2] + arr[i+ 1,j+1,2] - (arr[i-1, j - 1, 2] + 2 * arr[i,j-1, 2] + arr[i + 1, j - 1, 2])\n","                rv=arr[i+1,j-1,0] + 2*arr[i+1, j, 0] + arr[i+ 1,j+1,0] - (arr[i-1, j - 1, 0] + 2 * arr[i-1,j, 0] + arr[i - 1, j + 1, 0])\n","                gv=arr[i+1,j-1,1] + 2*arr[i+1, j, 1] + arr[i+ 1,j+1,1] - (arr[i-1, j - 1, 1] + 2 * arr[i-1,j, 1] + arr[i - 1, j + 1, 1])\n","                bv=arr[i+1,j-1,2] + 2*arr[i+1, j, 2] + arr[i+ 1,j+1,2] - (arr[i-1, j - 1, 2] + 2 * arr[i-1,j, 2] + arr[i - 1, j + 1, 2])\n","\n","                gxx = rh * rh + gh * gh + bh * bh\n","                gyy = rv * rv + gv * gv + bv * bv\n","                gxy = rh * rv + gh * gv + bh * bv\n","\n","                theta = round(math.atan(2.0 * gxy / (gxx - gyy + 0.00001))/ 2.0, 4)\n","                G1 = G2 = 0.0\n","\n","                G1 = math.sqrt(abs(0.5 * ((gxx + gyy) + (gxx - gyy) * math.cos(2.0 * theta) + 2.0 * gxy * math.sin(2.0 * theta))))\n","                G2=math.sqrt(abs(0.5*((gxx+gyy)+(gxx-gyy)*math.cos(2.0*(theta +(math.pi/2.0)))+ 2.0 * gxy * math.sin(2.0*(theta+ (math.pi / 2.0))))))\n","\n","                dir = 0\n","\n","                if max(G1, G2) == G1:\n","                    dir = 90.0 + theta * 180.0 / math.pi\n","                    ori[i, j] = int(dir * num / 360.0)\n","                else:\n","                    dir = 180.0 + (theta + math.pi / 2.0) * 180.0 / math.pi\n","                    ori[i, j] = int(dir * num / 360.0)\n","                if ori[i, j] >= num - 1:\n","                    ori[i, j] = num - 1\n","        return ori\n","\n","def compute(ColorX,ori,Lab,wid,hei,CSA,CSB,D):\n","        Arr = np.zeros(3 * wid * hei).reshape(wid, hei, 3)\n","        Arr = coOrdinateTransform(Lab, wid, hei)\n","        Matrix = np.zeros(CSA + CSB).reshape(CSA + CSB)\n","        hist = np.zeros(CSA + CSB).reshape(CSA + CSB)\n","\n","        # -------------------calculate the color difference of different directions------------\n","\n","        # ----------direction=0--------------------\n","\n","        for i in range(wid):\n","            for j in range(hei - D):\n","                value = 0.0\n","                if ori[i, j + D] == ori[i, j]:\n","                    value = math.sqrt(math.pow(Arr[i, j + D, 0] - Arr[i, j,0], 2) + math.pow(Arr[i, j + D, 1]- Arr[i, j, 1], 2) + math.pow(Arr[i,j + D, 2] - Arr[i, j, 2], 2))\n","                    Matrix[int(ColorX[i, j])] += value\n","                if ColorX[i, j + D] == ColorX[i, j]:\n","                    value = math.sqrt(math.pow(Arr[i, j + D, 0] - Arr[i, j,0], 2) + math.pow(Arr[i, j + D, 1]- Arr[i, j, 1], 2) + math.pow(Arr[i,j + D, 2] - Arr[i, j, 2], 2))\n","                    Matrix[int(ori[i, j] + CSA)] += value\n","\n","         # -----------direction=90---------------------\n","\n","        for i in range(wid - D):\n","            for j in range(hei):\n","                value = 0.0\n","                if ori[i + D, j] == ori[i, j]:\n","                    value = math.sqrt(math.pow(Arr[i + D, j, 0] - Arr[i, j,0], 2) + math.pow(Arr[i + D, j, 1]- Arr[i, j, 1], 2) + math.pow(Arr[i+ D, j, 2] - Arr[i, j, 2], 2))\n","                    Matrix[int(ColorX[i, j])] += value\n","                if ColorX[i + D, j] == ColorX[i, j]:\n","                    value = math.sqrt(math.pow(Arr[i + D, j, 0] - Arr[i, j,0], 2) + math.pow(Arr[i + D, j, 1]- Arr[i, j, 1], 2) + math.pow(Arr[i+ D, j, 2] - Arr[i, j, 2], 2))\n","                    Matrix[int(ori[i, j] + CSA)] += value\n","\n","       # -----------direction=135---------------------\n","        for i in range(wid - D):\n","            for j in range(hei - D):\n","                value = 0.0\n","                if ori[i + D, j + D] == ori[i, j]:\n","                    value = math.sqrt(math.pow(Arr[i + D, j + D, 0]- Arr[i, j, 0], 2) + math.pow(Arr[i+ D, j + D, 1] - Arr[i, j, 1], 2)+ math.pow(Arr[i + D, j + D, 2]- Arr[i, j, 2], 2))\n","                    Matrix[int(ColorX[i, j])] += value\n","                if ColorX[i + D, j + D] == ColorX[i, j]:\n","                    value = math.sqrt(math.pow(Arr[i + D, j + D, 0]- Arr[i, j, 0], 2) + math.pow(Arr[i+ D, j + D, 1] - Arr[i, j, 1], 2)+ math.pow(Arr[i + D, j + D, 2]- Arr[i, j, 2], 2))\n","                    Matrix[int(ori[i, j] + CSA)] += value\n","\n","        # -----------direction=45---------------------\n","\n","        for i in range(D, wid):\n","            for j in range(hei - D):\n","                value = 0.0\n","                if ori[i - D, j + D] == ori[i, j]:\n","                    value = math.sqrt(math.pow(Arr[i - D, j + D, 0]- Arr[i, j, 0], 2) + math.pow(Arr[i- D, j + D, 1] - Arr[i, j, 1], 2)+ math.pow(Arr[i - D, j + D, 2]- Arr[i, j, 2], 2))\n","                    Matrix[int(ColorX[i, j])] += value\n","                if ColorX[i - D, j + D] == ColorX[i, j]:\n","                    value = math.sqrt(math.pow(Arr[i - D, j + D, 0]- Arr[i, j, 0], 2) + math.pow(Arr[i- D, j + D, 1] - Arr[i, j, 1], 2)+ math.pow(Arr[i - D, j + D, 2]- Arr[i, j, 2], 2))\n","                    Matrix[int(ori[i, j] + CSA)] += value\n","\n","        for i in range(CSA + CSB):\n","            hist[i] = (Matrix[i]) / 4.0\n","\n","        return hist\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1ipxjm--sG3T"},"outputs":[],"source":["def img_center(arr, dim1, dim2):\n","    dimension = (dim1,dim2)\n","    dim = (dimension[0]/1.5,dimension[1]/1.5) #1.5\n","    width, height = arr.shape[1], arr.shape[0]\n","    crop_width = dim[0] if dim[0]<arr.shape[1] else arr.shape[1]\n","    crop_height = dim[1] if dim[1]<arr.shape[0] else arr.shape[0]\n","    mid_x, mid_y = int(width/2), int(height/2)\n","    cw2, ch2 = int(crop_width/2), int(crop_height/2)\n","    crop_img = arr[mid_y-ch2:mid_y+ch2, mid_x-cw2:mid_x+cw2]\n","    return crop_img"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sUgVfFg4sG3W"},"outputs":[],"source":["def extractLBP(img):\n","    lbp = local_binary_pattern(img, 24,3, method=\"uniform\")\n","    (hist, _) = np.histogram(lbp.ravel(),bins=np.arange(0, 27),range=(0, 26))\n","    hist = hist.astype(\"float\")\n","    hist /= (hist.sum() + (1e-7))\n","    return lbp,hist"]},{"cell_type":"markdown","metadata":{"id":"V1KPt_zNsG3Y"},"source":["# Clean train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UykBq1hmsG3a"},"outputs":[],"source":["classi = list(range(0,251))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l8rttlwBsG3b"},"outputs":[],"source":["dataset = DatasetDict({'train': dataset['train'].filter(lambda example: example['y'] in classi)})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FUEOPOg_sG3d"},"outputs":[],"source":["labels = dataset['train']['y']\n","labels = list(set(labels))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"referenced_widgets":["f6ebf3e197e04283aa776522deedf230","7262f35aa2e04008b7e6daef034b97ad"]},"id":"HybpEAULsG3f","outputId":"2593ac68-e193-4fde-f07c-3d5bc7865238"},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/1 [00:00<?, ?it/s]"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f6ebf3e197e04283aa776522deedf230","version_major":2,"version_minor":0},"text/plain":["Filter:   0%|          | 0/549 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["100%|██████████| 549/549 [07:15<00:00,  1.26it/s]\n","100%|██████████| 549/549 [05:53<00:00,  1.55it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7262f35aa2e04008b7e6daef034b97ad","version_major":2,"version_minor":0},"text/plain":["Filter:   0%|          | 0/549 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [13:20<00:00, 800.80s/it]\n"]}],"source":["# Initialization of the variable to 0\n","unione = 0\n","\n","# Iterating through labels using tqdm for progress visualization\n","for l in tqdm(labels):\n","\n","    # Filtering dataset based on the class\n","    filtered_data_dict = DatasetDict({'train': dataset['train'].filter(lambda example: example['y'] == l)})\n","\n","    # COLOR--------------------\n","    ## Color parameters\n","    lnum = 5\n","    anum = 2\n","    bnum = 2\n","    cnum = lnum * anum * bnum\n","    onum = 18\n","    N = cnum + onum\n","\n","    ## Color dictionary initialization\n","    diz = {}\n","\n","    # Iterating through images to compute color histograms\n","    for k in tqdm(range(len(filtered_data_dict[\"train\"][\"image\"]))):\n","        # Preprocessing image\n","        img = np.array(filtered_data_dict[\"train\"][\"image\"][k])\n","        dim = (64, 64)\n","        img = cv2.resize(img, dim)\n","        img = img_center(img, dim[0], dim[1])\n","\n","        # Converting image to LAB color space\n","        Lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n","\n","        # Initializing histogram and QuantizedImage\n","        hist = np.zeros(cnum + onum)\n","        width, height, channels = img.shape\n","        QuantizedImage = np.zeros(width * height).reshape(width, height)\n","\n","        L = a = b = 0\n","        for i in range(width):\n","            for j in range(height):\n","                L = int(Lab[i][j][0] * lnum / 100.0)\n","                if L >= lnum - 1:\n","                    L = lnum - 1\n","                elif L < 0:\n","                    L = 0\n","\n","                a = int(Lab[i][j][1] * anum / 254.0)\n","                if a >= anum - 1:\n","                    a = anum - 1\n","                elif a < 0:\n","                    a = 0\n","\n","                b = int(Lab[i][j][2] * bnum / 254.0)\n","                if b >= anum - 1:\n","                    b = anum - 1\n","                elif b < 0:\n","                    b = 0\n","\n","                QuantizedImage[i][j] = bnum * anum * L + bnum * a + b\n","\n","        lab = coOrdinateTransform(Lab, width, height)\n","        ori = maxgrad_and_mingrad_Lab(lab, onum, width, height)\n","        D = 1\n","\n","        # Computing histograms\n","        hist = compute(QuantizedImage, ori, Lab, width, height, cnum, onum, D)\n","        diz[k] = hist\n","\n","    # Mean histogram calculation\n","    array_values = np.array(list(diz.values()))\n","    median_array = np.median(array_values, axis=0)\n","    n_img = len(filtered_data_dict[\"train\"][\"image\"])\n","\n","    # Distance calculation\n","    ut = np.sum(array_values, axis=1)\n","    uq = np.sum(median_array)\n","    distance = np.zeros(n_img * N).reshape(n_img, N)\n","    for i in range(n_img):\n","        for j in range(N):\n","            distance[i, j] = (abs(diz[i][j] - median_array[j])) / (\n","                        abs(diz[i][j] + ut[i]) + abs(median_array[j] + uq))\n","    distanceSum = np.sum(distance, axis=1)\n","\n","    # Calculation of values to remove\n","    keys = np.arange(len(distanceSum), dtype=int)\n","    Imagedictionary = dict(zip(keys, distanceSum))\n","    sorted_images = sorted(Imagedictionary.items(), key=operator.itemgetter(1))\n","    twenty_percent_index = int(len(sorted_images) * 0.75)  # 75\n","    last_20_percent = sorted_images[twenty_percent_index:]\n","\n","    # List containing the most distant observations for color\n","    bad_list_color = [item[0] for item in last_20_percent]\n","\n","    # TEXTURE--------------------\n","    # Texture dictionary extraction\n","    diz_texture = {}\n","\n","    # Iterating through images to compute texture histograms\n","    for k in tqdm(range(len(filtered_data_dict[\"train\"][\"image\"]))):\n","        # Preprocessing image\n","        img = np.array(filtered_data_dict[\"train\"][\"image\"][k])\n","        dim = (64, 64)\n","        img = cv2.resize(img, dim)\n","        img = img_center(img, dim[0], dim[1])\n","        img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n","\n","        # Extracting LBP features\n","        lb, vektor = extractLBP(img)\n","        diz_texture[k] = np.array(vektor)\n","\n","    # Mean texture histogram calculation\n","    array_values = np.array(list(diz_texture.values()))\n","    median_array = np.median(array_values, axis=0)\n","\n","    # Distance calculation for texture\n","    ut = np.sum(array_values, axis=1)\n","    uq = np.sum(median_array)\n","    distance = np.zeros(n_img * 26).reshape(n_img, 26)\n","    for i in range(n_img):\n","        for j in range(26):\n","            distance[i, j] = (abs(diz_texture[i][j] - median_array[j])) / (\n","                        abs(diz_texture[i][j] + ut[i]) + abs(median_array[j] + uq))\n","    distanceSum = np.sum(distance, axis=1)\n","\n","    # Calculation of values to remove for texture\n","    keys = np.arange(len(distanceSum), dtype=int)\n","    Imagedictionary = dict(zip(keys, distanceSum))\n","    sorted_images = sorted(Imagedictionary.items(), key=operator.itemgetter(1))\n","    twenty_percent_index = int(len(sorted_images) * 0.75)  # 75\n","    last_20_percent = sorted_images[twenty_percent_index:]\n","\n","    # List containing the most distant observations for texture\n","    bad_list_texture = [item[0] for item in last_20_percent]\n","\n","    # ELIMINATION OF VALUES AND UNION ------------\n","    # Combining bad lists for color and texture\n","    bad_list = bad_list_texture + bad_list_color\n","    bad_list = list(set(bad_list))\n","\n","    # Filtering good images based on bad list\n","    good_image = filtered_data_dict['train']['image']\n","    for index in sorted(bad_list, reverse=True):\n","        del good_image[index]\n","\n","    # Creating a new dataset after filtering\n","    filt_data = DatasetDict({'train': filtered_data_dict['train'].filter(lambda example: example['image'] in good_image)})\n","\n","    # Union of datasets\n","    if unione == 0:\n","        unione = filt_data['train']\n","    else:\n","        unione = concatenate_datasets([unione, filt_data['train']])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"referenced_widgets":["a64ed1e48a9a424698e2e3e144277924"]},"id":"NUZi7PP1sG3k","outputId":"1e48e992-a1cc-4c5b-c889-f3ea75a1a3ad"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a64ed1e48a9a424698e2e3e144277924","version_major":2,"version_minor":0},"text/plain":["Saving the dataset (0/1 shards):   0%|          | 0/323 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["unione.save_to_disk(\"/content/train/Union\")"]},{"cell_type":"markdown","metadata":{"id":"r6RbDDpEsG3l"},"source":["# Data preparation for models"]},{"cell_type":"markdown","source":["##Train"],"metadata":{"id":"NsaetdNYn-5f"}},{"cell_type":"markdown","source":["New folder with clean train"],"metadata":{"id":"C5P8M6X6vART"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"qGixeeeDtmK1"},"outputs":[],"source":["source_folder = \"/content/train/train_set\"\n","destination_folder = \"/content/train/train_set_filtered\"\n","for file_name in unione:\n","    source_file_path = os.path.join(source_folder, file_name)\n","    destination_file_path = os.path.join(destination_folder, file_name)\n","\n","    # Check if the file exists before copying\n","    if os.path.exists(source_file_path):\n","        shutil.copy2(source_file_path, destination_file_path)\n","    else:\n","        print(f\"File not found: {file_name}\")"]},{"cell_type":"markdown","source":["Csv as clean as train-test"],"metadata":{"id":"fKFV6WLbvo-C"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"3PCMsCrItmK2"},"outputs":[],"source":["df = pd.read_csv(\"/content/drive/MyDrive/VIPM/Label/train_info_dirty.csv\")\n","filtered_df = df[df['file_name'].isin(unione)]\n","filtered_df['nome'] = filtered_df['file_name']\n","filtered_df.to_csv(\"/content/train/label.csv\", index=False)"]},{"cell_type":"markdown","source":["Create the folder by placing the images in subfolders indicating the classes they belong to"],"metadata":{"id":"BNdymx2ovx7u"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"u3i5K8VktmK5"},"outputs":[],"source":["source_folder = \"/content/train/train_set\"\n","destination_folder = \"/content/train/train_filtered_nest\"\n","for index, row in filtered_df.iterrows():\n","    file_name = row['file_name']\n","    classe_folder = str(row['y'])\n","\n","    # Create subfolder if not exists\n","    class_folder_path = os.path.join(destination_folder, classe_folder)\n","    os.makedirs(class_folder_path, exist_ok=True)\n","\n","    source_file_path = os.path.join(source_folder, file_name)\n","    destination_file_path = os.path.join(class_folder_path, file_name)\n","\n","    # Check if the file exists before copying\n","    if os.path.exists(source_file_path):\n","        shutil.copy2(source_file_path, destination_file_path)\n","    else:\n","        print(f\"File not found: {file_name}\")"]},{"cell_type":"markdown","metadata":{"id":"hXQoeur4tmK6"},"source":["##Test"]},{"cell_type":"code","source":["!unzip \"/content/drive/MyDrive/VIPM/Dataset/val_set.zip\" -d val_set"],"metadata":{"id":"Kfl2DSxfqq5k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!unzip \"/content/drive/MyDrive/VIPM/Dataset/val_set_degraded.zip\" -d val_set_degraded"],"metadata":{"id":"sbsNxAuJqrYp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Adding name column to label dataset for test"],"metadata":{"id":"pa-JY1H3wGbO"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"yzpLonjXtmK9"},"outputs":[],"source":["df = pd.read_csv(\"/content/drive/MyDrive/VIPM/Label/val_info.csv\", names=['file_name','y'])\n","df['nome'] = df['file_name']\n","df.to_csv(\"/content/val_set/metadata.csv\", index=False)\n","df.to_csv(\"/content/val_set_degraded/metadata.csv\", index=False)"]},{"cell_type":"markdown","source":["Create the folder by placing the images in subfolders indicating the classes they belong to"],"metadata":{"id":"oVbm4y_yyils"}},{"cell_type":"markdown","source":["###Clean test"],"metadata":{"id":"f6NG_XWYy2M5"}},{"cell_type":"code","source":["source_folder = \"/content/val_set/val_set\"\n","destination_folder = \"/content/val_set/val_set_nest\"\n","for index, row in df.iterrows():\n","    file_name = row['file_name']\n","    classe_folder = str(row['y'])\n","\n","    # Create subfolder if not exists\n","    class_folder_path = os.path.join(destination_folder, classe_folder)\n","    os.makedirs(class_folder_path, exist_ok=True)\n","\n","    source_file_path = os.path.join(source_folder, file_name)\n","    destination_file_path = os.path.join(class_folder_path, file_name)\n","\n","    # Check if the file exists before copying\n","    if os.path.exists(source_file_path):\n","        shutil.copy2(source_file_path, destination_file_path)\n","    else:\n","        print(f\"File not found: {file_name}\")"],"metadata":{"id":"kHi5mIDzyvLW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Test degraded"],"metadata":{"id":"z-qnYLHgy4T8"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"7sy4VN6jtmLB"},"outputs":[],"source":["source_folder = \"/content/val_set_degraded/val_set_degraded\"\n","destination_folder = \"/content/val_set_degraded/val_set_degraded_nest\"\n","for index, row in df.iterrows():\n","    file_name = row['file_name']\n","    classe_folder = str(row['y'])\n","\n","    # Create subfolder if not exists\n","    class_folder_path = os.path.join(destination_folder, classe_folder)\n","    os.makedirs(class_folder_path, exist_ok=True)\n","\n","    source_file_path = os.path.join(source_folder, file_name)\n","    destination_file_path = os.path.join(class_folder_path, file_name)\n","\n","    # Check if the file exists before copying\n","    if os.path.exists(source_file_path):\n","        shutil.copy2(source_file_path, destination_file_path)\n","    else:\n","        print(f\"File not found: {file_name}\")\n",""]},{"cell_type":"markdown","source":["**Reference**\n","\n","- CDH: [CBIR-Using-CDH](https://github.com/AdityaShaha/CBIR-Using-CDH)\n","- Texture: [Texture-Shape-And-Color-Extraction](https://github.com/faoezanf/Texture-Shape-And-Color-Extraction/blob/master/Texture%20Feature%20Extraction%20Using%20LBP.ipynb)"],"metadata":{"id":"nVD1v9gHL-cE"}}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}