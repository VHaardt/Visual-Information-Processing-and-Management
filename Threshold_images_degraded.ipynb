{"cells":[{"cell_type":"markdown","source":["# **Threshold images degraded**<br/>\n","**Master's Degree in Data Science (A.Y. 2023/2024)**<br/>\n","**University of Milano - Bicocca**<br/>\n","\n","Vittorio Haardt, Luca Porcelli"],"metadata":{"id":"YNMDuV62zrNo"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1hmZc8nrgVzt","executionInfo":{"status":"ok","timestamp":1706603737004,"user_tz":-60,"elapsed":28452,"user":{"displayName":"Luca Porcelli","userId":"09580591037146988201"}},"outputId":"92c784a4-74cf-4b63-8ad3-dc2e2a0cb324"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# Data Extraction Train"],"metadata":{"id":"aPtjHRPxz-gn"}},{"cell_type":"code","source":["!unzip \"/content/drive/MyDrive/VIPM/Dataset/val_set_degraded.zip\" -d val_set_degraded"],"metadata":{"id":"DbsDD80tT8fS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Installing packages and loading libraries"],"metadata":{"id":"SdkueJFggonG"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"CFP0crYDsdLR","outputId":"edb21f6b-60da-47f6-d902-d09d1616921c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706603758508,"user_tz":-60,"elapsed":21508,"user":{"displayName":"Luca Porcelli","userId":"09580591037146988201"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting brisque\n","  Downloading brisque-0.0.15-py3-none-any.whl (135 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/135.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m133.1/135.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.6/135.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from brisque) (1.23.5)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from brisque) (0.19.3)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from brisque) (1.11.4)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from brisque) (4.8.0.76)\n","Collecting libsvm (from brisque)\n","  Downloading libsvm-3.23.0.4.tar.gz (170 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.6/170.6 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->brisque) (3.2.1)\n","Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->brisque) (9.4.0)\n","Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->brisque) (2.31.6)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->brisque) (2023.12.9)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->brisque) (1.5.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->brisque) (23.2)\n","Building wheels for collected packages: libsvm\n","  Building wheel for libsvm (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for libsvm: filename=libsvm-3.23.0.4-cp310-cp310-linux_x86_64.whl size=251408 sha256=632bb9d231d6908c00b7b6b7ec94baa572a346c0666a4df4cb617c7c8a7f86a8\n","  Stored in directory: /root/.cache/pip/wheels/79/c7/19/a8c85928f8e629654b8e1adb3c8091f0bb77344d0ee9954a85\n","Successfully built libsvm\n","Installing collected packages: libsvm, brisque\n","Successfully installed brisque-0.0.15 libsvm-3.23.0.4\n"]}],"source":["pip install brisque"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KXYnNTDtsdLS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706603761986,"user_tz":-60,"elapsed":3485,"user":{"displayName":"Luca Porcelli","userId":"09580591037146988201"}},"outputId":"32946af7-31e1-442a-ea9e-9432ae659907"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/libsvm/svm.py:149: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n","  def csr_to_problem_jit(l, x_val, x_ind, x_rowptr, prob_val, prob_ind, prob_rowptr, indx_start):\n"]}],"source":["import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from brisque import BRISQUE\n","from skimage import io\n","from tqdm import tqdm\n","import pandas as pd\n","from sklearn.metrics import confusion_matrix, accuracy_score, precision_score\n","import os\n","import random\n","from PIL import Image"]},{"cell_type":"markdown","source":["# Manual Labeling Method for Single Prints"],"metadata":{"id":"5SR5gwy5iTJh"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"_x5vp3F6sdLT"},"outputs":[],"source":["# Path to the folder containing the images\n","image_folder = '/content/val_set_degraded'\n","\n","# List to save the image name and class\n","images_and_classes = []\n","\n","# Get the list of all files in the folder\n","image_files = [f for f in os.listdir(image_folder) if os.path.isfile(os.path.join(image_folder, f))]\n","\n","# Select randomly 100 images\n","random_images = random.sample(image_files, 100)\n","\n","# Loop through the selected images\n","for image_name in tqdm(random_images):\n","    # Create the full path of the image\n","    image_path = os.path.join(image_folder, image_name)\n","\n","    # Load and display the image\n","    img = Image.open(image_path)\n","    img.show()\n","\n","    # Ask for the class input\n","    image_class = input(f\"Enter the class for the image {image_name}: \")\n","\n","    # Save the image name and class in the list\n","    images_and_classes.append({'name': image_name, 'class': image_class})\n","\n","# Print the final list\n","print(\"Final list of images and classes:\")\n","print(images_and_classes)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iz1q8pkmsdLT"},"outputs":[],"source":["df = pd.DataFrame(immagini_e_classi)\n","df['classe'] = pd.to_numeric(df['classe'])"]},{"cell_type":"markdown","source":["# Optimization of Image Classification"],"metadata":{"id":"WE_wMHKIigbH"}},{"cell_type":"markdown","source":["Testing Thresholds to Identify and Distinguish between Images with Noise, Blurry, Compressed and Normal"],"metadata":{"id":"JnpIH8iWYE2m"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"4DJsgETTsdLU"},"outputs":[],"source":["def is_valid(image, soglia):\n","    # Convert image to HSV color space\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n","    # Calculate histogram of saturation channel\n","    s = cv2.calcHist([image], [1], None, [256], [0, 256])\n","    return s[-1] > soglia"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dqUeaVn2sdLU"},"outputs":[],"source":["li_var = [20, 25, 30, 35, 40, 50, 60, 70, 80, 90, 100]\n","obj = BRISQUE(url=False)\n","li_s = [5, 10, 15, 20, 25, 30, 40, 50, 60, 80, 90]\n","soglia = [2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000]\n","results = []\n","\n","for k in tqdm(soglia):\n","    for soglia_var in li_var:\n","        for soglia_s in li_s:\n","            df = pd.DataFrame(immagini_e_classi)  # Assuming immagini_e_classi is defined\n","            df['classe'] = pd.to_numeric(df['classe'])\n","            df['ris'] = None\n","\n","            for i in range(len(df)):\n","                path = \"/content/val_set_degraded\" + df.iloc[i, 0]\n","                img = cv2.imread(path)\n","                gt = df.iloc[i, 1]\n","\n","                grey = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","                var = cv2.Laplacian(grey, cv2.CV_64F).var()\n","                if var < soglia_var:\n","                    ris = 3  # blurred\n","                else:\n","                    img2 = cv2.cvtColor(io.imread(path), cv2.COLOR_RGB2BGR)\n","                    val = is_valid(img2, soglia=k)[0]  # Assuming is_valid returns a tuple\n","                    if val:\n","                        ris = 2  # noise\n","                        print()\n","                    else:\n","                        s = obj.score(img)\n","                        if s > soglia_s:\n","                            ris = 4  # poor quality\n","                        else:\n","                            ris = 1  # normal\n","                df.iloc[i, 2] = ris\n","            df['classe'] = pd.to_numeric(df['classe'])\n","            df['ris'] = pd.to_numeric(df['ris'])\n","            conf_matrix = confusion_matrix(df['classe'], df['ris'])\n","            accuracy = accuracy_score(df['classe'], df['ris'])\n","            precision_per_class = precision_score(df['classe'], df['ris'], average=None)\n","            results.append([[soglia_var, k, soglia_s], [accuracy, precision_per_class]])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0XvjK4EusdLU"},"outputs":[],"source":["massimo = max(risultati, key=lambda x: x[1][0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qQu6OmiRsdLU"},"outputs":[],"source":["deg_lab = pd.read_csv(\"/content/val_set_degraded/metadata.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aKcrx945sdLU"},"outputs":[],"source":["deg_lab['stato'] = None"]},{"cell_type":"markdown","source":["# Classification of Degraded Images"],"metadata":{"id":"7AU9veJEjs0Z"}},{"cell_type":"markdown","source":["Application of Optimized Thresholds across the Set"],"metadata":{"id":"2YTGnYufY0pR"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"cLplW-CIsdLU"},"outputs":[],"source":["soglia_var = float(massimo[0][0])\n","k = float(massimo[0][1])\n","soglia_s = float(massimo[0][2])\n","\n","for i in range(len(deg_lab)):\n","    path = \"/content/val_set_degraded\" + deg_lab.iloc[i, 0]\n","    img = cv2.imread(path)\n","\n","    grey = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","    var = cv2.Laplacian(grey, cv2.CV_64F).var()\n","\n","    if var < soglia_var:\n","        ris = 3  # blurred\n","    else:\n","        img2 = cv2.cvtColor(io.imread(path), cv2.COLOR_RGB2BGR)\n","        val = is_valid(img2, soglia=k)[0]  # Assuming is_valid returns a tuple\n","        if val:\n","            ris = 2  # noise\n","            print()\n","        else:\n","            s = obj.score(img)\n","            if s > soglia_s:\n","                ris = 4  # poor quality\n","            else:\n","                ris = 1  # normal\n","\n","    deg_lab.at[i, 'stato'] = ris"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BoJawQ7OsdLV"},"outputs":[],"source":["#deg_lab.to_csv('/content/drive/MyDrive/VIPM/Dataset/deg_lab.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8LjxO8kJsdLV"},"outputs":[],"source":["deg_lab = pd.read_csv(\"/content/drive/MyDrive/VIPM/Dataset/deg_lab.csv\")"]},{"cell_type":"markdown","source":["The degraded images are modified and saved in a folder:\n","\n","* Remove noise: Application of Non-local Means Denoising, a filtering technique that exploits pixel similarity to reduce noise while preserving important details. It considers the entire image to estimate the noise distribution. Subsequent application of bilateral filtering, where both spatial distance and color distance are considered to preserve edges while reducing noise.\n","\n","* Remove blur: Application of a 2D filter with the kernel_blur, which assigns a higher weight to the central pixel, maintaining the sum of weights at 25 to preserve the overall brightness of the image. Subsequent application of Non-local Means Denoising.\n","\n","* Poor quality: Application of Non-local Means Denoising. Subsequent application of a 2D filter with the kernel_qual, which assigns a higher weight to the central pixel and negative weights to surrounding pixels, promoting detail enhancement and reducing artifacts introduced by JPEG compression."],"metadata":{"id":"3wZtnJaj8exQ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"rF5a2EQmsdLV"},"outputs":[],"source":["# Define for image processing\n","kernel_blur = np.array([[-1, -1, -1, -1, -1],\n","                        [-1, -1, -1, -1, -1],\n","                        [-1, -1, 25, -1, -1],\n","                        [-1, -1, -1, -1, -1],\n","                        [-1, -1, -1, -1, -1]])\n","\n","kernel_qual = np.array([[0, -1, 0],\n","                        [-1, 5, -1],\n","                        [0, -1, 0]])\n","\n","# Initialize BRISQUE object\n","bri = BRISQUE(url=False)\n","\n","# Destination folder\n","destination_folder = \"/content/drive/MyDrive/VIPM/Dataset/deg_pul.zip\"\n","\n","# Loop through each item in the 'deg_lab' list\n","for i in range(len(deg_lab)):\n","    path = \"/content/val_set_degraded\" + deg_lab.iloc[i, 0]\n","    img = cv2.imread(path)\n","    img2 = None\n","\n","    # Check the degradation type and apply corresponding image processing\n","    if deg_lab.iloc[i, 3] == 2:  # Remove noise\n","        img2 = cv2.fastNlMeansDenoising(img, None, 30, 10)\n","        img2 = cv2.bilateralFilter(img2, 18, 40, 40)\n","        # Compare BRISQUE scores and choose the modified image if it has a lower score\n","        if bri.score(img) > bri.score(img2):\n","            img = img2\n","    elif deg_lab.iloc[i, 3] == 3:  # Remove blur\n","        img2 = cv2.filter2D(img, -1, kernel_blur)\n","        img2 = cv2.fastNlMeansDenoising(img2, None, 30, 5)\n","        # Compare BRISQUE scores and choose the modified image if it has a lower score\n","        if bri.score(img) > bri.score(img2):\n","            img = img2\n","    elif deg_lab.iloc[i, 3] == 4:  # Poor quality\n","        img2 = cv2.fastNlMeansDenoising(img, None, 29, 5)\n","        img2 = cv2.filter2D(img2, -1, kernel_qual)\n","        # Compare BRISQUE scores and choose the modified image if it has a lower score\n","        if bri.score(img) > bri.score(img2):\n","            img = img2\n","    else:\n","        pass  # Do nothing for other cases\n","\n","    # Extract the filename without extension\n","    file_name_without_extension = os.path.splitext(os.path.basename(path))[0]\n","\n","    # Save the modified image\n","    filename = os.path.join(destination_folder, f\"{file_name_without_extension}.jpg\")\n","    cv2.imwrite(filename, img)\n",""]},{"cell_type":"markdown","source":["**Reference**\n","\n","- Blur: [blur-detection-with-opencv](https://pyimagesearch.com/2015/09/07/blur-detection-with-opencv/)\n","- BRISQUE: [brisque](https://pypi.org/project/brisque/)"],"metadata":{"id":"U0UPpC0ANiRG"}}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}